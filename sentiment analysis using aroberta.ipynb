{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1041a1b8-3ee5-44ad-a037-409712a1137f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import csv\n",
    "import urllib.request\n",
    "\n",
    "import nltk\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import seaborn as sns\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacbcf5b-b1b2-4636-8fce-3a9674ef0146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess text (username and link placeholders)\n",
    "def preprocess(text):\n",
    "    new_text = []\n",
    " \n",
    " \n",
    "    for t in text.split(\" \"):\n",
    "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = 'http' if t.startswith('http') else t\n",
    "        new_text.append(t)\n",
    "    return \" \".join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c69e9f35-22be-4431-b5c1-fd03758f09db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbcafbce9cfb4ac59ab415cb74acb0e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pk\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:127: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\pk\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "# Tasks:\n",
    "# emoji, emotion, hate, irony, offensive, sentiment\n",
    "# stance/abortion, stance/atheism, stance/climate, stance/feminist, stance/hillary\n",
    "\n",
    "task='sentiment'\n",
    "MODEL = f\"cardiffnlp/twitter-roberta-base-{task}\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "\n",
    "# download label mapping\n",
    "labels=[]\n",
    "mapping_link = f\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/{task}/mapping.txt\"\n",
    "with urllib.request.urlopen(mapping_link) as f:\n",
    "    html = f.read().decode('utf-8').split(\"\\n\")\n",
    "    csvreader = csv.reader(html, delimiter='\\t')\n",
    "labels = [row[1] for row in csvreader if len(row) > 1]\n",
    "\n",
    "# PT\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "model.save_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14b5bc05-b12b-4dae-a917-c661e24df7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.read_csv(r\"C:/Users/pk/Projects/balakot/public.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f385a0d1-92ce-4e8f-8f44-80ad6ebed603",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\pk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stemmer = nltk.SnowballStemmer(\"english\")\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "stopword=set(stopwords.words('english'))\n",
    "\n",
    "def clean(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', ' ', text)\n",
    "    text = re.sub('\\r', ' ', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    text = [word for word in text.split(' ') if word not in stopword]\n",
    "    text=\" \".join(text)\n",
    "    text = [stemmer.stem(word) for word in text.split(' ')]\n",
    "    text=\" \".join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85c2abbc-8bbf-4f89-a5a9-e1b7f253cd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['tweet'] = df3['text'].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0fdeded7-a03d-426e-89b0-c0425fd9e631",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df3['tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4356b8c2-f096-4e94-a1ea-9e50424d0906",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)\n",
    "scores = output[0][0].detach().numpy()\n",
    "scores = softmax(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f5d8cc8-7783-4c5a-aba0-a09abc142c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.22724693, 0.751812  , 0.02094114], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db92c560-f0a9-42f7-b7ab-cb43915ee27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) neutral 0.7518\n",
      "2) negative 0.2272\n",
      "3) positive 0.0209\n"
     ]
    }
   ],
   "source": [
    "# # TF\n",
    "# model = TFAutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "# model.save_pretrained(MODEL)\n",
    "\n",
    "# text = \"Good night ðŸ˜Š\"\n",
    "# encoded_input = tokenizer(text, return_tensors='tf')\n",
    "# output = model(encoded_input)\n",
    "# scores = output[0][0].numpy()\n",
    "# scores = softmax(scores)\n",
    "\n",
    "ranking = np.argsort(scores)\n",
    "ranking = ranking[::-1]\n",
    "for i in range(scores.shape[0]):\n",
    "    l = labels[ranking[i]]\n",
    "    s = scores[ranking[i]]\n",
    "    print(f\"{i+1}) {l} {np.round(float(s), 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8c78e6c1-9862-4624-9e6b-419e2d933dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_classifier(text):\n",
    "    encoded_input = tokenizer(text, return_tensors='pt')\n",
    "    output = model(**encoded_input)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "\n",
    "\n",
    "    ranking = np.argsort(scores)\n",
    "    ranking = ranking[::-1]\n",
    "    for i in range(scores.shape[0]):\n",
    "        l = labels[ranking[0]] \n",
    "        #print(l)\n",
    "        s = scores[ranking[0]] \n",
    "        #print(f\"{i+1}) {l} {np.round(float(s), 4)}\")\n",
    "        classification = l\n",
    "\n",
    "    \n",
    "    return classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d63fef85-a482-4ac2-96d7-581e7217b3b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neutral'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_classifier(text[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3cb548-4a11-4a1a-8897-6473b53ae8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['sentiment'] = df3['tweet'].apply(sentiment_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8ac29012-81f3-4144-9aa7-99b57b3c4c60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>user_username</th>\n",
       "      <th>source</th>\n",
       "      <th>created_at</th>\n",
       "      <th>user_location</th>\n",
       "      <th>user_name</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>like_count</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>user_tweet_count</th>\n",
       "      <th>user_list_count</th>\n",
       "      <th>user_followers_count</th>\n",
       "      <th>user_following_count</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4758</td>\n",
       "      <td>Indian aircrafts intruded from Muzafarabad sec...</td>\n",
       "      <td>OfficialDGISPR</td>\n",
       "      <td>Twitter for iPad</td>\n",
       "      <td>2019-02-26T01:36:30.000Z</td>\n",
       "      <td>Pakistan</td>\n",
       "      <td>DG ISPR</td>\n",
       "      <td>10406</td>\n",
       "      <td>40211</td>\n",
       "      <td>2685</td>\n",
       "      <td>1222</td>\n",
       "      <td>1322</td>\n",
       "      <td>5891405</td>\n",
       "      <td>0</td>\n",
       "      <td>indian aircraft intrud muzafarabad sector face...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6693</td>\n",
       "      <td>1000 kgs bombs dropped on terror camps with pi...</td>\n",
       "      <td>majorgauravarya</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>2019-02-26T03:49:02.000Z</td>\n",
       "      <td>India</td>\n",
       "      <td>Major Gaurav Arya (Retd)</td>\n",
       "      <td>10404</td>\n",
       "      <td>34533</td>\n",
       "      <td>669</td>\n",
       "      <td>9833</td>\n",
       "      <td>647</td>\n",
       "      <td>1415589</td>\n",
       "      <td>367</td>\n",
       "      <td>kgs bomb drop terror camp pin point accuraci ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53217</td>\n",
       "      <td>I visited mountain area of Jabba 25 km away fr...</td>\n",
       "      <td>HamidMirPAK</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>2019-02-27T09:38:38.000Z</td>\n",
       "      <td>Islamabad, Pakistan</td>\n",
       "      <td>Hamid Mir</td>\n",
       "      <td>8184</td>\n",
       "      <td>28732</td>\n",
       "      <td>1178</td>\n",
       "      <td>41320</td>\n",
       "      <td>4030</td>\n",
       "      <td>7557234</td>\n",
       "      <td>488</td>\n",
       "      <td>visit mountain area jabba  km away balakot tod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1645</td>\n",
       "      <td>We must recognise the sacrifices of our parami...</td>\n",
       "      <td>RahulGandhi</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>2019-02-25T08:15:27.000Z</td>\n",
       "      <td>12, Tughlak Lane, New Delhi</td>\n",
       "      <td>Rahul Gandhi</td>\n",
       "      <td>7520</td>\n",
       "      <td>25055</td>\n",
       "      <td>450</td>\n",
       "      <td>6331</td>\n",
       "      <td>4772</td>\n",
       "      <td>21467331</td>\n",
       "      <td>275</td>\n",
       "      <td>must recognis sacrific paramilitari forc like ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20358</td>\n",
       "      <td>What an explosive morning ! As india celebrate...</td>\n",
       "      <td>TandonRaveena</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>2019-02-26T06:30:04.000Z</td>\n",
       "      <td>Planet Earth</td>\n",
       "      <td>Raveena Tandon</td>\n",
       "      <td>3465</td>\n",
       "      <td>21943</td>\n",
       "      <td>153</td>\n",
       "      <td>22900</td>\n",
       "      <td>1418</td>\n",
       "      <td>2421885</td>\n",
       "      <td>405</td>\n",
       "      <td>explos morn  india celebr  salut  braveheart m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57910</th>\n",
       "      <td>57907</td>\n",
       "      <td>The IAF_MCC confirms the \\r\\nthe crash earlier...</td>\n",
       "      <td>QadirQd</td>\n",
       "      <td>IFTTT</td>\n",
       "      <td>2019-02-27T18:54:13.000Z</td>\n",
       "      <td>Vododara, India</td>\n",
       "      <td>Qadir Qd ðŸ‡®ðŸ‡³</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>154886</td>\n",
       "      <td>22</td>\n",
       "      <td>4538</td>\n",
       "      <td>92</td>\n",
       "      <td>iafmcc confirm   crash earlier morn condol fam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57911</th>\n",
       "      <td>57908</td>\n",
       "      <td>We 130 crore indian are celebrating we have av...</td>\n",
       "      <td>Global_Bakait</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>2019-02-27T18:54:12.000Z</td>\n",
       "      <td>India</td>\n",
       "      <td>Global-à¤¬à¤•à¥ˆà¤¤ ðŸ‘¤</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22837</td>\n",
       "      <td>4</td>\n",
       "      <td>492</td>\n",
       "      <td>2139</td>\n",
       "      <td>crore indian celebr avang pulwama  crore pak ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57912</th>\n",
       "      <td>57909</td>\n",
       "      <td>Our war is against terrorism &amp;amp; people supp...</td>\n",
       "      <td>Crazy_Ayush1</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>2019-02-27T18:54:06.000Z</td>\n",
       "      <td>Blockchain, Internet</td>\n",
       "      <td>Ayush Sharma</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>378</td>\n",
       "      <td>1</td>\n",
       "      <td>282</td>\n",
       "      <td>66</td>\n",
       "      <td>war terror amp peopl support     dear indian  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57913</th>\n",
       "      <td>57911</td>\n",
       "      <td>Response #surgicalstrike #paf #pakistan Salute...</td>\n",
       "      <td>hamzaawanwafa</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>2019-02-27T18:53:10.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hamza Awan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>216</td>\n",
       "      <td>respons surgicalstrik paf pakistan salut pakis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57914</th>\n",
       "      <td>57913</td>\n",
       "      <td>Abhinandan the man without fear,\\r\\nReal son o...</td>\n",
       "      <td>Skant1968</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>2019-02-27T18:53:00.000Z</td>\n",
       "      <td>MZN ,UP ,India</td>\n",
       "      <td>Shashi kant sharma</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>462</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>90</td>\n",
       "      <td>abhinandan man without fear  real son india  s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57915 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                               text  \\\n",
       "0            4758  Indian aircrafts intruded from Muzafarabad sec...   \n",
       "1            6693  1000 kgs bombs dropped on terror camps with pi...   \n",
       "2           53217  I visited mountain area of Jabba 25 km away fr...   \n",
       "3            1645  We must recognise the sacrifices of our parami...   \n",
       "4           20358  What an explosive morning ! As india celebrate...   \n",
       "...           ...                                                ...   \n",
       "57910       57907  The IAF_MCC confirms the \\r\\nthe crash earlier...   \n",
       "57911       57908  We 130 crore indian are celebrating we have av...   \n",
       "57912       57909  Our war is against terrorism &amp; people supp...   \n",
       "57913       57911  Response #surgicalstrike #paf #pakistan Salute...   \n",
       "57914       57913  Abhinandan the man without fear,\\r\\nReal son o...   \n",
       "\n",
       "         user_username               source                created_at  \\\n",
       "0       OfficialDGISPR     Twitter for iPad  2019-02-26T01:36:30.000Z   \n",
       "1      majorgauravarya   Twitter for iPhone  2019-02-26T03:49:02.000Z   \n",
       "2          HamidMirPAK   Twitter for iPhone  2019-02-27T09:38:38.000Z   \n",
       "3          RahulGandhi   Twitter for iPhone  2019-02-25T08:15:27.000Z   \n",
       "4        TandonRaveena   Twitter for iPhone  2019-02-26T06:30:04.000Z   \n",
       "...                ...                  ...                       ...   \n",
       "57910          QadirQd                IFTTT  2019-02-27T18:54:13.000Z   \n",
       "57911    Global_Bakait  Twitter for Android  2019-02-27T18:54:12.000Z   \n",
       "57912     Crazy_Ayush1  Twitter for Android  2019-02-27T18:54:06.000Z   \n",
       "57913    hamzaawanwafa  Twitter for Android  2019-02-27T18:53:10.000Z   \n",
       "57914        Skant1968  Twitter for Android  2019-02-27T18:53:00.000Z   \n",
       "\n",
       "                     user_location                 user_name  retweet_count  \\\n",
       "0                         Pakistan                   DG ISPR          10406   \n",
       "1                            India  Major Gaurav Arya (Retd)          10404   \n",
       "2              Islamabad, Pakistan                 Hamid Mir           8184   \n",
       "3      12, Tughlak Lane, New Delhi              Rahul Gandhi           7520   \n",
       "4                     Planet Earth            Raveena Tandon           3465   \n",
       "...                            ...                       ...            ...   \n",
       "57910              Vododara, India               Qadir Qd ðŸ‡®ðŸ‡³              0   \n",
       "57911                        India             Global-à¤¬à¤•à¥ˆà¤¤ ðŸ‘¤              0   \n",
       "57912         Blockchain, Internet              Ayush Sharma              0   \n",
       "57913                          NaN                Hamza Awan              0   \n",
       "57914               MZN ,UP ,India        Shashi kant sharma              1   \n",
       "\n",
       "       like_count  quote_count  user_tweet_count  user_list_count  \\\n",
       "0           40211         2685              1222             1322   \n",
       "1           34533          669              9833              647   \n",
       "2           28732         1178             41320             4030   \n",
       "3           25055          450              6331             4772   \n",
       "4           21943          153             22900             1418   \n",
       "...           ...          ...               ...              ...   \n",
       "57910           0            0            154886               22   \n",
       "57911           0            0             22837                4   \n",
       "57912           0            0               378                1   \n",
       "57913           0            0                92                0   \n",
       "57914           0            0               462                0   \n",
       "\n",
       "       user_followers_count  user_following_count  \\\n",
       "0                   5891405                     0   \n",
       "1                   1415589                   367   \n",
       "2                   7557234                   488   \n",
       "3                  21467331                   275   \n",
       "4                   2421885                   405   \n",
       "...                     ...                   ...   \n",
       "57910                  4538                    92   \n",
       "57911                   492                  2139   \n",
       "57912                   282                    66   \n",
       "57913                    17                   216   \n",
       "57914                    19                    90   \n",
       "\n",
       "                                                   tweet  \n",
       "0      indian aircraft intrud muzafarabad sector face...  \n",
       "1       kgs bomb drop terror camp pin point accuraci ...  \n",
       "2      visit mountain area jabba  km away balakot tod...  \n",
       "3      must recognis sacrific paramilitari forc like ...  \n",
       "4      explos morn  india celebr  salut  braveheart m...  \n",
       "...                                                  ...  \n",
       "57910  iafmcc confirm   crash earlier morn condol fam...  \n",
       "57911   crore indian celebr avang pulwama  crore pak ...  \n",
       "57912  war terror amp peopl support     dear indian  ...  \n",
       "57913  respons surgicalstrik paf pakistan salut pakis...  \n",
       "57914  abhinandan man without fear  real son india  s...  \n",
       "\n",
       "[57915 rows x 15 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
